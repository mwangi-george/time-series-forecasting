[
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#introduction",
    "href": "001-hyperparameter-tuning-example/index.html#introduction",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "1 Introduction",
    "text": "1 Introduction\nSales forecasting used to be a game of spreadsheets, gut feeling, and crossed fingers. Today, machine learning lets us move beyond guesswork and start making predictions that actually learn from data.\nIn this post, we’ll explore how to build practical sales forecasting models using R, a language loved for its statistical depth and elegant data tooling. Without drowning in theory, we’ll walk through how historical sales data can be transformed into forward-looking insights using modern machine learning techniques.\nWhether you’re an analyst trying to improve forecast accuracy, a data scientist working in R, or a business professional curious about how machine learning really works under the hood, this guide will show you how to turn past sales into smarter decisions about the future."
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#workspace-setup",
    "href": "001-hyperparameter-tuning-example/index.html#workspace-setup",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "2 Workspace setup",
    "text": "2 Workspace setup\nTo build our forecasting models, we’ll work entirely within the tidy modeling ecosystem in R, which emphasizes readable code, reproducibility, and modular workflows. We’ll rely on three core machine learning libraries—modeltime, tidymodels, and workflowsets—alongside two essential data and time-series packages: dplyr and timetk.\nAt the center of this workflow is the Modeltime ecosystem, which extends tidymodels with first-class support for time series forecasting. Modeltime provides a unified interface for fitting, calibrating, comparing, and evaluating both classical statistical models and modern machine learning approaches (such as boosted trees and neural networks) using tidy data principles. By integrating seamlessly with timetk, it makes feature engineering for time-based data—lags, rolling statistics, and seasonal signatures—both intuitive and scalable.\ntidymodels gives us a consistent framework for preprocessing, model specification, and evaluation, while workflowsets allows us to experiment with multiple models and feature combinations in a structured and repeatable way. Together with dplyr for data manipulation and timetk for time-series visualization and feature engineering, this setup lets us move cleanly from raw historical sales data to production-ready forecasts.\n\n# Machine Learning\nlibrary(tidymodels)   # modeling framework\nlibrary(modeltime)    # time series forecasting workflows built on tidymodels\nlibrary(workflowsets) # manage and compare many model/preprocess workflows at once\n\n# Core\nlibrary(timetk)       # time series plotting helpers, and feature engineering\nlibrary(dplyr)        # core data manipulation\n\n# Avoid scientific notation for large values (e.g., 250000 instead of 2.5e+05)\noptions(scipen = 999)\n\n# ------------------------------------------------------------------------------\n# Enable parallel processing for model training\n# ------------------------------------------------------------------------------\n\n# Detect available physical CPU cores (optional)\nparallel::detectCores(logical = FALSE)\n\n[1] 8\n\n# Start a parallel backend using 2 cores\nparallel_start(2, .method = \"parallel\")"
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#dataset-overview",
    "href": "001-hyperparameter-tuning-example/index.html#dataset-overview",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "3 Dataset overview",
    "text": "3 Dataset overview\nThe dataset used in this tutorial represents the historical monthly sales of a single product (Product Y) for a fictional company called Metricon. Each observation corresponds to the total sales recorded in a given month, making the data naturally suited for time series analysis and forecasting.\nThe dataset contains two columns:\n\ndate – the first day of each month, representing the sales period\nvalue – the total sales volume for Product Y in that month\n\nThe data spans multiple consecutive years, providing enough history to observe long-term trends, seasonal patterns, and periods of growth or volatility. In the sections that follow, we’ll first explore the structure of the data by inspecting the first and last few records, then visualize the full time series to better understand its overall behavior before applying machine learning models for forecasting.\n\n# ------------------------------------------------------------------------------\n# Load and prepare the sales dataset\n# ------------------------------------------------------------------------------\n\nraw_sales_df &lt;- read.csv(\n  \"data/sales_timeseries_monthly.csv\",\n) |&gt;\n  mutate(\n    date = lubridate::mdy(date)  # Parse date column into Date type\n  )\n\n\n# ------------------------------------------------------------------------------\n# Quick data inspection\n# ------------------------------------------------------------------------------\n\n# Preview the first 3 observations\nraw_sales_df |&gt;\n  slice_head(n = 3)\n\n\n  \n\n\n# Preview the last 3 observations\nraw_sales_df |&gt;\n  slice_tail(n = 3)\n\n\n  \n\n\n# ------------------------------------------------------------------------------\n# Visualize historical sales trend\n# ------------------------------------------------------------------------------\n\nraw_sales_df |&gt;\n  plot_time_series(\n    .date_var = date,\n    .value    = value,\n    .title    = \"Product Y Sales Trend over Time\",\n    .y_lab = \"Sales in USD\"\n  )\n\n\n\n\n\nThe historical sales trend for Product Y at Metricon shows a business that has steadily grown over time, but not without meaningful volatility along the way. In the earlier years of the series, sales fluctuate around a lower baseline, with noticeable month-to-month swings that suggest an immature or stabilizing market phase. From around 2020 onward, a clear upward trajectory begins to emerge. By the most recent periods, sales reach their highest levels in the dataset, indicating strong momentum and increasing demand for Product Y."
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#anomaly-detection",
    "href": "001-hyperparameter-tuning-example/index.html#anomaly-detection",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "4 Anomaly detection",
    "text": "4 Anomaly detection\nBefore building forecasting models, it’s important to understand whether the historical data contains unusual or unexpected behavior. The anomaly diagnostics plot highlights periods where sales of Product Y significantly deviate from the expected range, flagging potential outliers caused by events such as promotions, supply disruptions, or reporting issues. Identifying these anomalies early helps ensure that forecasting models learn genuine patterns rather than noise, ultimately leading to more reliable and robust predictions.\n\n# ------------------------------------------------------------------------------\n# Visualize anomaly diagnostics in the sales time series\n# ------------------------------------------------------------------------------\n\nraw_sales_df |&gt;\n  plot_anomaly_diagnostics(\n    .date_var    = date,\n    .value       = value,\n    .title       = \"Product Y Anomaly Diagnostics\",\n    .y_lab = \"Sales in USD\",\n    .alpha       = 0.10,   # Sensitivity level for anomaly detection\n    .legend_show = FALSE  # Hide legend for a cleaner visualization\n  )\n\n\n\n\n\nThe code chunk below focuses on cleaning the historical sales data before forecasting. Using anomaly detection, we identify months where Product Y’s sales significantly deviate from the expected pattern. Instead of removing these observations entirely, the workflow replaces anomalous values with a cleaned estimate that better reflects the underlying trend to preserve the continuity of the time series while preventing extreme values from distorting downstream machine learning models. Finally, the cleaned series is replotted to visually confirm that the long-term trend remains intact, but with reduced noise.\n\n# ------------------------------------------------------------------------------\n# Detect anomalies in the historical sales data\n# ------------------------------------------------------------------------------\n\nanomaly_results_df &lt;- raw_sales_df |&gt;\n  anomalize(\n    .date_var  = date,\n    .value     = value,\n    .iqr_alpha = 0.10   # Sensitivity level for anomaly detection\n  )\n\n# Inspect a few records to understand the anomaly flags\nanomaly_results_df |&gt;\n  slice_head(n = 3) |&gt;\n  select(date, observed, anomaly, trend, observed_clean)\n\n\n  \n\n\n# ------------------------------------------------------------------------------\n# Replace anomalous values with cleaned estimates\n# ------------------------------------------------------------------------------\n\ncleaned_sales_df &lt;- anomaly_results_df |&gt;\n  transmute(\n    date,\n    value = if_else(\n      anomaly == \"Yes\",\n      observed_clean,  # Use cleaned value when anomaly is detected\n      observed         # Otherwise keep the original observation\n    )\n  )\n\n\n# ------------------------------------------------------------------------------\n# Visualize the cleaned time series\n# ------------------------------------------------------------------------------\n\ncleaned_sales_df |&gt;\n  plot_time_series(\n    .date_var = date,\n    .value    = value,\n    .title    = \"Product Y Sales Trend over Time (Anomalies Adjusted)\",\n    .y_lab = \"Sales in USD\"\n  )"
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#traintest-splitting-for-time-series",
    "href": "001-hyperparameter-tuning-example/index.html#traintest-splitting-for-time-series",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "5 Train–test splitting for time series",
    "text": "5 Train–test splitting for time series\nBefore training any forecasting models, we split the cleaned sales data into training and testing sets using a temporal split. Unlike random sampling, time series data must respect chronological order to avoid data leakage. In this setup, the model is trained on all historical observations up to a cutoff point and evaluated on the most recent 12 months, simulating a real-world forecasting scenario. The cumulative training window allows the model to learn from an expanding history over time, while the visualization of the cross-validation plan helps confirm that the split is both temporally sound and aligned with how forecasts will be used in practice.\n\n# ------------------------------------------------------------------------------\n# Train / test split (temporal holdout)\n# - We keep time order intact to avoid leakage.\n# - The last 12 months are held out for testing.\n# - cumulative = TRUE uses an expanding training window.\n# ------------------------------------------------------------------------------\n\nsales_split &lt;- cleaned_sales_df |&gt;\n  time_series_split(\n    date_var    = date,\n    assess      = \"12 months\",\n    cumulative  = TRUE\n  )\n\n# View the split summary (prints the rsample split object)\nsales_split\n\n&lt;Analysis/Assess/Total&gt;\n&lt;61/12/73&gt;\n\n# ------------------------------------------------------------------------------\n# Visualize the split as a CV plan (train vs test over time)\n# ------------------------------------------------------------------------------\n\nsales_split |&gt;\n  tk_time_series_cv_plan() |&gt;\n  plot_time_series_cv_plan(\n    .date_var = date,\n    .value    = value,\n    .y_lab    = \"Sales in USD\",\n    .title    = \"Train/Test Temporal Split (12-Month Holdout)\"\n  )"
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#feature-engineering-for-time-series-modeling",
    "href": "001-hyperparameter-tuning-example/index.html#feature-engineering-for-time-series-modeling",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "6 Feature engineering for time series modeling",
    "text": "6 Feature engineering for time series modeling\nTo enable machine learning models to learn from temporal patterns, we transform the raw date information into meaningful numerical features using a preprocessing recipe. The time series signature expands the date column into multiple components such as trend, seasonality, and calendar-based signals, which are then cleaned and standardized for modeling. Redundant and zero-variance features are removed to reduce noise, while categorical time features are one-hot encoded to ensure compatibility with most machine learning algorithms. This structured feature engineering step allows models to capture complex time-dependent behavior beyond what raw timestamps alone can provide.\n\n# ------------------------------------------------------------------------------\n# Feature engineering (tidymodels recipe)\n# - Convert the date into rich time-based features (trend + seasonality signals)\n# - Remove the original date column to avoid leakage / redundancy\n# - Normalize the numeric time index for ML models that benefit from scaling\n# - Drop zero-variance predictors (features that never change)\n# - One-hot encode categorical time features (month labels, weekdays, etc.)\n# ------------------------------------------------------------------------------\n\nsales_recipe &lt;- recipe(value ~ date, data = training(sales_split)) |&gt;\n  step_timeseries_signature(date) |&gt;\n  step_rm(date) |&gt;                \n  step_normalize(date_index.num) |&gt;\n  step_zv(all_predictors()) |&gt;\n  step_dummy(all_nominal_predictors(), one_hot = TRUE)\n\n# Inspect the recipe steps\nsales_recipe\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 1\n\n\n\n\n\n── Operations \n\n\n• Timeseries signature features from: date\n\n\n• Variables removed: date\n\n\n• Centering and scaling for: date_index.num\n\n\n• Zero variance filter on: all_predictors()\n\n\n• Dummy variables from: all_nominal_predictors()"
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#model-specification",
    "href": "001-hyperparameter-tuning-example/index.html#model-specification",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "7 Model Specification",
    "text": "7 Model Specification\nWith our time-based features ready, the next step is to define the models we want to try. Instead of relying on a single configuration, we evaluate multiple XGBoost models by varying key hyperparameters such as learning rate, tree depth, and regularization strength.\n\n\n\n\n\n\nNote\n\n\n\nXGBoost (Extreme Gradient Boosting) is a high-performance machine learning algorithm that builds powerful predictive models by combining many decision trees in a sequential, error-correcting manner. It is widely used for regression and classification tasks because it efficiently captures complex nonlinear patterns while offering strong accuracy, scalability, and regularization to prevent overfitting.\n\n\n\n# ------------------------------------------------------------------------------\n# Model specification (XGBoost regression)\n# ------------------------------------------------------------------------------\n\n\n# Hyperparameter grid (learn_rate + depth + min_n + loss_reduction)\nxgb_param_grid &lt;- tidyr::crossing(\n  learn_rate     = c(0.001, 0.01, 0.1, 0.2, 0.35),\n  tree_depth     = c(2L, 4L, 6L, 8L),\n  min_n          = c(2L, 5L, 10L, 20L),\n  loss_reduction = c(0, 0.01, 0.1, 1)\n)\n\n# ------------------------------------------------------------------------------\n# Create model specifications for each hyperparameter combination\n# ------------------------------------------------------------------------------\n\nxgb_spec_tbl &lt;- create_model_grid(\n  grid         = xgb_param_grid,\n  f_model_spec = boost_tree,\n  engine_name  = \"xgboost\",\n  mode         = \"regression\"\n)\n\n# Review the model specification table (includes parameters + model objects)\nxgb_spec_tbl\n\n\n  \n\n\n# Extract the list of parsnip model specifications (useful for workflowsets)\nxgb_model_list &lt;- xgb_spec_tbl$.models\n\n# Preview first 2 specs\nxgb_model_list[1:2]\n\n[[1]]\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  min_n = 2\n  tree_depth = 2\n  learn_rate = 0.001\n  loss_reduction = 0\n\nComputational engine: xgboost \n\n\n[[2]]\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  min_n = 2\n  tree_depth = 2\n  learn_rate = 0.001\n  loss_reduction = 0.01\n\nComputational engine: xgboost"
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#workflow-sets",
    "href": "001-hyperparameter-tuning-example/index.html#workflow-sets",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "8 Workflow sets",
    "text": "8 Workflow sets\nWorkflow sets allow us to systematically combine preprocessing recipes and model specifications into comparable modeling pipelines. In this case, we pair a single time-series recipe with multiple XGBoost configurations, creating a collection of untrained workflows that can be fit and evaluated consistently.\n\n# ------------------------------------------------------------------------------\n# Workflow sets\n# - Combine the preprocessing recipe with multiple XGBoost model specifications\n# - Each workflow represents one unique recipe–model combination\n# - Workflows are created unfitted and will be trained during evaluation\n# ------------------------------------------------------------------------------\n\nsales_workflow_set &lt;- workflow_set(\n  preproc = list(sales_recipe = sales_recipe),\n  models  = xgb_model_list,\n  cross   = TRUE\n)\n\n# Inspect the workflow set\nsales_workflow_set"
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#fitting-using-parallel-backend",
    "href": "001-hyperparameter-tuning-example/index.html#fitting-using-parallel-backend",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "9 Fitting Using Parallel Backend",
    "text": "9 Fitting Using Parallel Backend\nWe will now train all recipe–model combinations by fitting the workflow set on the training portion of the time series. By enabling parallel execution, each workflow is trained concurrently across multiple CPU cores, significantly reducing total runtime while providing clear progress feedback during the fitting process.\n\n# ------------------------------------------------------------------------------\n# Parallel model training (workflow set fitting)\n# - Fit all workflows on the training data\n# - Enable parallel processing to speed up computation\n# - Verbose output shows progress for each workflow\n# ------------------------------------------------------------------------------\n\nfitted_models_tbl &lt;- sales_workflow_set |&gt;\n  modeltime_fit_workflowset(\n    data = training(sales_split),\n    control = control_fit_workflowset(\n      verbose   = TRUE,  # Display progress during fitting\n      allow_par = TRUE   # Use the active parallel backend\n    )\n  )\n\nUsing existing parallel backend with 2 workers...\n\n\n Beginning Parallel Loop | 0.009 seconds\n\n\n Finishing parallel backend. Clusters are remaining open. | 7.456 seconds\n\n\n Close clusters by running: `parallel_stop()`.\n\n\n Total time | 7.456 seconds\n\n# Inspect fitted workflows\nfitted_models_tbl"
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#accuracy-assessment",
    "href": "001-hyperparameter-tuning-example/index.html#accuracy-assessment",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "10 Accuracy assessment",
    "text": "10 Accuracy assessment\nAfter fitting the models, we evaluate their out-of-sample performance by calibrating each workflow on the test set and computing standard forecast accuracy metrics. Comparing these results allows us to identify the best-performing configuration, with Model 277 achieving the lowest Mean Absolute Error (MAE) and therefore providing the most accurate forecasts on unseen data.\n\n# ------------------------------------------------------------------------------\n# Model evaluation and accuracy comparison\n# - Calibrate fitted models on the test set\n# - Compute standard forecast accuracy metrics\n# - Rank models to identify the best performer\n# ------------------------------------------------------------------------------\n\ncalibration_tbl &lt;- fitted_models_tbl |&gt;\n  modeltime_calibrate(new_data = testing(sales_split))\n\nmodel_accuracy_tbl &lt;- calibration_tbl |&gt;\n  modeltime_accuracy() |&gt;\n  arrange(mae) |&gt; \n  slice_min(mae, n =10)\n\n# Display accuracy results in a readable table\ntable_modeltime_accuracy(\n  model_accuracy_tbl,\n  .interactive = FALSE\n)\n\n\n\n\n\n\n\nAccuracy Table\n\n\n.model_id\n.model_desc\n.type\nmae\nmape\nmase\nsmape\nrmse\nrsq\n\n\n\n\n277\nSALES_RECIPE_BOOST_TREE_277\nTest\n43447.35\n18.21\n0.65\n18.77\n53267.77\n0.36\n\n\n278\nSALES_RECIPE_BOOST_TREE_278\nTest\n43447.35\n18.21\n0.65\n18.77\n53267.77\n0.36\n\n\n279\nSALES_RECIPE_BOOST_TREE_279\nTest\n43447.35\n18.21\n0.65\n18.77\n53267.77\n0.36\n\n\n280\nSALES_RECIPE_BOOST_TREE_280\nTest\n43447.35\n18.21\n0.65\n18.77\n53267.77\n0.36\n\n\n261\nSALES_RECIPE_BOOST_TREE_261\nTest\n43564.50\n18.25\n0.65\n18.68\n54005.01\n0.32\n\n\n262\nSALES_RECIPE_BOOST_TREE_262\nTest\n43564.50\n18.25\n0.65\n18.68\n54005.01\n0.32\n\n\n263\nSALES_RECIPE_BOOST_TREE_263\nTest\n43564.50\n18.25\n0.65\n18.68\n54005.01\n0.32\n\n\n264\nSALES_RECIPE_BOOST_TREE_264\nTest\n43564.50\n18.25\n0.65\n18.68\n54005.01\n0.32\n\n\n257\nSALES_RECIPE_BOOST_TREE_257\nTest\n44264.16\n18.58\n0.66\n19.17\n55486.98\n0.28\n\n\n258\nSALES_RECIPE_BOOST_TREE_258\nTest\n44264.16\n18.58\n0.66\n19.17\n55486.98\n0.28\n\n\n259\nSALES_RECIPE_BOOST_TREE_259\nTest\n44264.16\n18.58\n0.66\n19.17\n55486.98\n0.28\n\n\n260\nSALES_RECIPE_BOOST_TREE_260\nTest\n44264.16\n18.58\n0.66\n19.17\n55486.98\n0.28"
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#forecast-assessment",
    "href": "001-hyperparameter-tuning-example/index.html#forecast-assessment",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "11 Forecast Assessment",
    "text": "11 Forecast Assessment\nTo complement the numerical accuracy metrics, we visually assess how each model’s forecasts compare against the actual sales during the testing period. This side-by-side visualization helps reveal differences in trend capture, responsiveness to changes, and overall forecast stability that may not be fully apparent from error metrics alone.\n\n# ------------------------------------------------------------------------------\n# Forecast assessment (visual comparison on test set)\n# - Generate forecasts for each fitted model on the test period\n# - Overlay predictions with actual historical sales\n# - Retain underlying data for further inspection if needed\n# ------------------------------------------------------------------------------\n\nforecast_comparison_tbl &lt;- calibration_tbl |&gt;\n  # filter for the 10 best models \n  filter(.model_id %in% model_accuracy_tbl$.model_id) |&gt; \n  modeltime_forecast(\n    new_data    = testing(sales_split),\n    actual_data = cleaned_sales_df,\n    keep_data   = TRUE\n  )\n\n# Plot forecasts vs actuals for visual evaluation\nforecast_comparison_tbl |&gt;\n  plot_modeltime_forecast(\n    .legend_max_width = 10, # For mobile screens\n    .conf_interval_show = FALSE,\n    .title = \"Model Forecasts vs Actual Sales (Test Set)\"\n  )"
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#refit-to-full-dataset-forecast-forward",
    "href": "001-hyperparameter-tuning-example/index.html#refit-to-full-dataset-forecast-forward",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "12 Refit to Full Dataset & Forecast Forward",
    "text": "12 Refit to Full Dataset & Forecast Forward\nAfter ranking models on the test set, we select the top performer (lowest MAE) and then refit it using the full cleaned dataset so it can learn from all available history. Finally, we generate a 24-month ahead forecast and plot it alongside the historical sales to visualize the expected future trajectory.\n\n# ------------------------------------------------------------------------------\n# Select the best model (lowest MAE)\n# - slice_min() can return ties, so we break ties deterministically with_mae then\n#   take the first row.\n# ------------------------------------------------------------------------------\n\nbest_model_id &lt;- model_accuracy_tbl |&gt;\n  arrange(mae, .model_id) |&gt;\n  slice_head(n = 1) |&gt;\n  pull(.model_id)\n\n# ------------------------------------------------------------------------------\n# Refit the winning model on the full dataset\n# - Re-training on all history improves the final model before forecasting\n# ------------------------------------------------------------------------------\n\nfinal_xgb_tbl &lt;- calibration_tbl |&gt;\n  filter(.model_id == best_model_id) |&gt;\n  modeltime_refit(data = cleaned_sales_df)\n\n# ------------------------------------------------------------------------------\n# Forecast the next 24 months and visualize\n# ------------------------------------------------------------------------------\n\nfuture_forecast_tbl &lt;- final_xgb_tbl |&gt;\n  modeltime_forecast(\n    h = \"24 months\",\n    actual_data = cleaned_sales_df\n  )\n\nfuture_forecast_tbl |&gt;\n  plot_modeltime_forecast(\n    .legend_show = FALSE,\n    .title = \"Final XGBoost Sales Forecast for Product Y (24-Month Horizon)\",\n    .y_lab = \"Sales in USD\"\n  )\n\n\n\n\n# Forecasts dataset\nfuture_forecast_tbl |&gt; \n  filter(.key == \"prediction\") |&gt; \n  select(\n    date = .index, \n    lower_limit = .conf_lo,\n    point_estimate = .value,\n    upper_limit = .conf_hi\n  )\n\n\n  \n\n\n\n\nparallel_stop()"
  },
  {
    "objectID": "001-hyperparameter-tuning-example/index.html#conclusion",
    "href": "001-hyperparameter-tuning-example/index.html#conclusion",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "13 Conclusion",
    "text": "13 Conclusion\nIn this post, we walked through an end-to-end machine learning workflow for sales forecasting in R, starting from data exploration and anomaly detection, through feature engineering, model specification, parallel training, evaluation, and finally producing a forward-looking forecast using XGBoost. This approach offers clear benefits: it leverages rich time-based features, uses a robust validation strategy, and produces forecasts that are both data-driven and reproducible. At the same time, it’s important to recognize the limitations, machine learning models like XGBoost can be sensitive to hyperparameter choices, require careful feature engineering, and may not always generalize best across all datasets or business contexts.\nFor Metricon, these forecasts can directly inform decisions such as inventory planning, budgeting, production scheduling, and scenario analysis by providing a clearer view of expected future demand. However, no single model is universally optimal. In the next post, we’ll broaden the analysis by training and comparing multiple forecasting algorithms on the same sales data to assess whether alternative models can outperform XGBoost and under what conditions, bringing us closer to a truly model-agnostic, decision-ready forecasting strategy.\nWritten by\nGeorge Mwangi is a software engineer and data professional specializing in machine learning, data analytics, and digital health systems design & development. His work focuses on building practical, production-ready solutions for forecasting, decision support, and data-driven planning. He is particularly interested in applying modern data science tools to solve real-world business and public health sector problems.\n\nYou can connect with George on:\n\nLinkedIn: https://www.linkedin.com/in/georgemwangikenya\nGitHub: https://github.com/mwangi-george\n\n\n\nSession Information\n\n\n\n\nsessionInfo()\n\nR version 4.5.2 (2025-10-31)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Tahoe 26.2\n\nMatrix products: default\nBLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Africa/Nairobi\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.4    timetk_2.9.0       modeltime_1.3.2    yardstick_1.3.2   \n [5] workflowsets_1.1.1 workflows_1.3.0    tune_2.0.0         tidyr_1.3.1       \n [9] tailor_0.1.0       rsample_1.3.1      recipes_1.3.1      purrr_1.1.0       \n[13] parsnip_1.3.3      modeldata_1.5.1    infer_1.0.9        ggplot2_3.5.2     \n[17] dplyr_1.1.4        dials_1.4.2        scales_1.4.0       broom_1.0.10      \n[21] tidymodels_1.4.1  \n\nloaded via a namespace (and not attached):\n [1] rlang_1.1.6         magrittr_2.0.3      furrr_0.3.1        \n [4] compiler_4.5.2      vctrs_0.6.5         lhs_1.2.0          \n [7] stringr_1.5.1       pkgconfig_2.0.3     fastmap_1.2.0      \n[10] backports_1.5.0     labeling_0.4.3      rmarkdown_2.29     \n[13] prodlim_2025.04.28  xfun_0.52           jsonlite_2.0.0     \n[16] parallel_4.5.2      R6_2.6.1            stringi_1.8.7      \n[19] RColorBrewer_1.1-3  StanHeaders_2.32.10 parallelly_1.45.0  \n[22] rpart_4.1.24        xgboost_1.7.11.1    Rcpp_1.0.14        \n[25] iterators_1.0.14    knitr_1.50          future.apply_1.20.0\n[28] zoo_1.8-14          Matrix_1.7-4        splines_4.5.2      \n[31] nnet_7.3-20         timechange_0.3.0    tidyselect_1.2.1   \n[34] rstudioapi_0.17.1   yaml_2.3.10         timeDate_4041.110  \n[37] doParallel_1.0.17   codetools_0.2-20    listenv_0.9.1      \n[40] lattice_0.22-7      tibble_3.3.0        withr_3.0.2        \n[43] evaluate_1.0.4      future_1.58.0       survival_3.8-3     \n[46] RcppParallel_5.1.10 xml2_1.3.8          xts_0.14.1         \n[49] pillar_1.10.2       foreach_1.5.2       plotly_4.11.0      \n[52] generics_0.1.4      globals_0.18.0      class_7.3-23       \n[55] glue_1.8.0          lazyeval_0.2.2      tools_4.5.2        \n[58] data.table_1.17.6   gower_1.0.2         forcats_1.0.0      \n[61] fs_1.6.6            grid_4.5.2          crosstalk_1.2.1    \n[64] ipred_0.9-15        cli_3.6.5           DiceDesign_1.10    \n[67] viridisLite_0.4.2   lava_1.8.1          gt_1.1.0           \n[70] gtable_0.3.6        GPfit_1.0-9         sass_0.4.10        \n[73] digest_0.6.37       htmlwidgets_1.6.4   farver_2.1.2       \n[76] htmltools_0.5.8.1   lifecycle_1.0.4     hardhat_1.4.2      \n[79] httr_1.4.7          MASS_7.3-65         sparsevctrs_0.3.4"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "George Mwangi",
    "section": "",
    "text": "Hi there,\nMy name is George Mwangi, a software engineer and data professional specializing in machine learning, data analytics, and digital health systems design & development. My work focuses on building practical, production-ready solutions for forecasting, decision support, and data-driven planning. I am particularly interested in applying modern data science tools to solve real-world business and public health sector problems.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSales Forecasting with Machine Learning in R\n\n\nAn end-to-end, practical workflow using Modeltime, Tidymodels, and XGBoost\n\n\nA practical walkthrough for forecasting monthly sales using Modeltime, Tidymodels, and XGBoost in R.\n\n\n\n\n\nJan 27, 2026\n\n\nGeorge N. Mwangi\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#introduction",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#introduction",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "1 Introduction",
    "text": "1 Introduction\nSales forecasting used to be a game of spreadsheets, gut feeling, and crossed fingers. Today, machine learning lets us move beyond guesswork and start making predictions that actually learn from data.\nIn this post, we’ll explore how to build practical sales forecasting models using R, a language loved for its statistical depth and elegant data tooling. Without drowning in theory, we’ll walk through how historical sales data can be transformed into forward-looking insights using modern machine learning techniques.\nWhether you’re an analyst trying to improve forecast accuracy, a data scientist working in R, or a business professional curious about how machine learning really works under the hood, this guide will show you how to turn past sales into smarter decisions about the future."
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#workspace-setup",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#workspace-setup",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "2 Workspace setup",
    "text": "2 Workspace setup\nTo build our forecasting models, we’ll work entirely within the tidy modeling ecosystem in R, which emphasizes readable code, reproducibility, and modular workflows. We’ll rely on three core machine learning libraries—modeltime, tidymodels, and workflowsets—alongside two essential data and time-series packages: dplyr and timetk.\nAt the center of this workflow is the Modeltime ecosystem, which extends tidymodels with first-class support for time series forecasting. Modeltime provides a unified interface for fitting, calibrating, comparing, and evaluating both classical statistical models and modern machine learning approaches (such as boosted trees and neural networks) using tidy data principles. By integrating seamlessly with timetk, it makes feature engineering for time-based data—lags, rolling statistics, and seasonal signatures—both intuitive and scalable.\ntidymodels gives us a consistent framework for preprocessing, model specification, and evaluation, while workflowsets allows us to experiment with multiple models and feature combinations in a structured and repeatable way. Together with dplyr for data manipulation and timetk for time-series visualization and feature engineering, this setup lets us move cleanly from raw historical sales data to production-ready forecasts.\n\n# Machine Learning\nlibrary(tidymodels)   # modeling framework\nlibrary(modeltime)    # time series forecasting workflows built on tidymodels\nlibrary(workflowsets) # manage and compare many model/preprocess workflows at once\n\n# Core\nlibrary(timetk)       # time series plotting helpers, and feature engineering\nlibrary(dplyr)        # core data manipulation\n\n# Avoid scientific notation for large values (e.g., 250000 instead of 2.5e+05)\noptions(scipen = 999)\n\n# ------------------------------------------------------------------------------\n# Enable parallel processing for model training\n# ------------------------------------------------------------------------------\n\n# Detect available physical CPU cores (optional)\nparallel::detectCores(logical = FALSE)\n\n[1] 8\n\n# Start a parallel backend using 2 cores\nparallel_start(2, .method = \"parallel\")"
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#dataset-overview",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#dataset-overview",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "3 Dataset overview",
    "text": "3 Dataset overview\nThe dataset used in this tutorial represents the historical monthly sales of a single product (Product Y) for a fictional company called Metricon. Each observation corresponds to the total sales recorded in a given month, making the data naturally suited for time series analysis and forecasting.\nThe dataset contains two columns:\n\ndate – the first day of each month, representing the sales period\nvalue – the total sales volume for Product Y in that month\n\nThe data spans multiple consecutive years, providing enough history to observe long-term trends, seasonal patterns, and periods of growth or volatility. In the sections that follow, we’ll first explore the structure of the data by inspecting the first and last few records, then visualize the full time series to better understand its overall behavior before applying machine learning models for forecasting.\n\n# ------------------------------------------------------------------------------\n# Load and prepare the sales dataset\n# ------------------------------------------------------------------------------\n\nraw_sales_df &lt;- read.csv(\n  \"data/sales_timeseries_monthly.csv\",\n) |&gt;\n  mutate(\n    date = lubridate::mdy(date)  # Parse date column into Date type\n  )\n\n\n# ------------------------------------------------------------------------------\n# Quick data inspection\n# ------------------------------------------------------------------------------\n\n# Preview the first 3 observations\nraw_sales_df |&gt;\n  slice_head(n = 3)\n\n\n  \n\n\n# Preview the last 3 observations\nraw_sales_df |&gt;\n  slice_tail(n = 3)\n\n\n  \n\n\n# ------------------------------------------------------------------------------\n# Visualize historical sales trend\n# ------------------------------------------------------------------------------\n\nraw_sales_df |&gt;\n  plot_time_series(\n    .date_var = date,\n    .value    = value,\n    .title    = \"Product Y Sales Trend over Time\",\n    .y_lab = \"Sales in USD\"\n  )\n\n\n\n\n\nThe historical sales trend for Product Y at Metricon shows a business that has steadily grown over time, but not without meaningful volatility along the way. In the earlier years of the series, sales fluctuate around a lower baseline, with noticeable month-to-month swings that suggest an immature or stabilizing market phase. From around 2020 onward, a clear upward trajectory begins to emerge. By the most recent periods, sales reach their highest levels in the dataset, indicating strong momentum and increasing demand for Product Y."
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#anomaly-detection",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#anomaly-detection",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "4 Anomaly detection",
    "text": "4 Anomaly detection\nBefore building forecasting models, it’s important to understand whether the historical data contains unusual or unexpected behavior. The anomaly diagnostics plot highlights periods where sales of Product Y significantly deviate from the expected range, flagging potential outliers caused by events such as promotions, supply disruptions, or reporting issues. Identifying these anomalies early helps ensure that forecasting models learn genuine patterns rather than noise, ultimately leading to more reliable and robust predictions.\n\n# ------------------------------------------------------------------------------\n# Visualize anomaly diagnostics in the sales time series\n# ------------------------------------------------------------------------------\n\nraw_sales_df |&gt;\n  plot_anomaly_diagnostics(\n    .date_var    = date,\n    .value       = value,\n    .title       = \"Product Y Anomaly Diagnostics\",\n    .y_lab = \"Sales in USD\",\n    .alpha       = 0.10,   # Sensitivity level for anomaly detection\n    .legend_show = FALSE  # Hide legend for a cleaner visualization\n  )\n\n\n\n\n\nThe code chunk below focuses on cleaning the historical sales data before forecasting. Using anomaly detection, we identify months where Product Y’s sales significantly deviate from the expected pattern. Instead of removing these observations entirely, the workflow replaces anomalous values with a cleaned estimate that better reflects the underlying trend to preserve the continuity of the time series while preventing extreme values from distorting downstream machine learning models. Finally, the cleaned series is replotted to visually confirm that the long-term trend remains intact, but with reduced noise.\n\n# ------------------------------------------------------------------------------\n# Detect anomalies in the historical sales data\n# ------------------------------------------------------------------------------\n\nanomaly_results_df &lt;- raw_sales_df |&gt;\n  anomalize(\n    .date_var  = date,\n    .value     = value,\n    .iqr_alpha = 0.10   # Sensitivity level for anomaly detection\n  )\n\n# Inspect a few records to understand the anomaly flags\nanomaly_results_df |&gt;\n  slice_head(n = 3) |&gt;\n  select(date, observed, anomaly, trend, observed_clean)\n\n\n  \n\n\n# ------------------------------------------------------------------------------\n# Replace anomalous values with cleaned estimates\n# ------------------------------------------------------------------------------\n\ncleaned_sales_df &lt;- anomaly_results_df |&gt;\n  transmute(\n    date,\n    value = if_else(\n      anomaly == \"Yes\",\n      observed_clean,  # Use cleaned value when anomaly is detected\n      observed         # Otherwise keep the original observation\n    )\n  )\n\n\n# ------------------------------------------------------------------------------\n# Visualize the cleaned time series\n# ------------------------------------------------------------------------------\n\ncleaned_sales_df |&gt;\n  plot_time_series(\n    .date_var = date,\n    .value    = value,\n    .title    = \"Product Y Sales Trend over Time (Anomalies Adjusted)\",\n    .y_lab = \"Sales in USD\"\n  )"
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#traintest-splitting-for-time-series",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#traintest-splitting-for-time-series",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "5 Train–test splitting for time series",
    "text": "5 Train–test splitting for time series\nBefore training any forecasting models, we split the cleaned sales data into training and testing sets using a temporal split. Unlike random sampling, time series data must respect chronological order to avoid data leakage. In this setup, the model is trained on all historical observations up to a cutoff point and evaluated on the most recent 12 months, simulating a real-world forecasting scenario. The cumulative training window allows the model to learn from an expanding history over time, while the visualization of the cross-validation plan helps confirm that the split is both temporally sound and aligned with how forecasts will be used in practice.\n\n# ------------------------------------------------------------------------------\n# Train / test split (temporal holdout)\n# - We keep time order intact to avoid leakage.\n# - The last 12 months are held out for testing.\n# - cumulative = TRUE uses an expanding training window.\n# ------------------------------------------------------------------------------\n\nsales_split &lt;- cleaned_sales_df |&gt;\n  time_series_split(\n    date_var    = date,\n    assess      = \"12 months\",\n    cumulative  = TRUE\n  )\n\n# View the split summary (prints the rsample split object)\nsales_split\n\n&lt;Analysis/Assess/Total&gt;\n&lt;61/12/73&gt;\n\n# ------------------------------------------------------------------------------\n# Visualize the split as a CV plan (train vs test over time)\n# ------------------------------------------------------------------------------\n\nsales_split |&gt;\n  tk_time_series_cv_plan() |&gt;\n  plot_time_series_cv_plan(\n    .date_var = date,\n    .value    = value,\n    .y_lab    = \"Sales in USD\",\n    .title    = \"Train/Test Temporal Split (12-Month Holdout)\"\n  )"
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#feature-engineering-for-time-series-modeling",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#feature-engineering-for-time-series-modeling",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "6 Feature engineering for time series modeling",
    "text": "6 Feature engineering for time series modeling\nTo enable machine learning models to learn from temporal patterns, we transform the raw date information into meaningful numerical features using a preprocessing recipe. The time series signature expands the date column into multiple components such as trend, seasonality, and calendar-based signals, which are then cleaned and standardized for modeling. Redundant and zero-variance features are removed to reduce noise, while categorical time features are one-hot encoded to ensure compatibility with most machine learning algorithms. This structured feature engineering step allows models to capture complex time-dependent behavior beyond what raw timestamps alone can provide.\n\n# ------------------------------------------------------------------------------\n# Feature engineering (tidymodels recipe)\n# - Convert the date into rich time-based features (trend + seasonality signals)\n# - Remove the original date column to avoid leakage / redundancy\n# - Normalize the numeric time index for ML models that benefit from scaling\n# - Drop zero-variance predictors (features that never change)\n# - One-hot encode categorical time features (month labels, weekdays, etc.)\n# ------------------------------------------------------------------------------\n\nsales_recipe &lt;- recipe(value ~ date, data = training(sales_split)) |&gt;\n  step_timeseries_signature(date) |&gt;\n  step_rm(date) |&gt;                \n  step_normalize(date_index.num) |&gt;\n  step_zv(all_predictors()) |&gt;\n  step_dummy(all_nominal_predictors(), one_hot = TRUE)\n\n# Inspect the recipe steps\nsales_recipe\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 1\n\n\n\n\n\n── Operations \n\n\n• Timeseries signature features from: date\n\n\n• Variables removed: date\n\n\n• Centering and scaling for: date_index.num\n\n\n• Zero variance filter on: all_predictors()\n\n\n• Dummy variables from: all_nominal_predictors()"
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#model-specification",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#model-specification",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "7 Model Specification",
    "text": "7 Model Specification\nWith our time-based features ready, the next step is to define the models we want to try. Instead of relying on a single configuration, we evaluate multiple XGBoost models by varying key hyperparameters such as learning rate, tree depth, and regularization strength.\n\n\n\n\n\n\nNote\n\n\n\nXGBoost (Extreme Gradient Boosting) is a high-performance machine learning algorithm that builds powerful predictive models by combining many decision trees in a sequential, error-correcting manner. It is widely used for regression and classification tasks because it efficiently captures complex nonlinear patterns while offering strong accuracy, scalability, and regularization to prevent overfitting.\n\n\n\n# ------------------------------------------------------------------------------\n# Model specification (XGBoost regression)\n# ------------------------------------------------------------------------------\n\n\n# Hyperparameter grid (learn_rate + depth + min_n + loss_reduction)\nxgb_param_grid &lt;- tidyr::crossing(\n  learn_rate     = c(0.001, 0.01, 0.1, 0.2, 0.35),\n  tree_depth     = c(2L, 4L, 6L, 8L),\n  min_n          = c(2L, 5L, 10L, 20L),\n  loss_reduction = c(0, 0.01, 0.1, 1)\n)\n\n# ------------------------------------------------------------------------------\n# Create model specifications for each hyperparameter combination\n# ------------------------------------------------------------------------------\n\nxgb_spec_tbl &lt;- create_model_grid(\n  grid         = xgb_param_grid,\n  f_model_spec = boost_tree,\n  engine_name  = \"xgboost\",\n  mode         = \"regression\"\n)\n\n# Review the model specification table (includes parameters + model objects)\nxgb_spec_tbl\n\n\n  \n\n\n# Extract the list of parsnip model specifications (useful for workflowsets)\nxgb_model_list &lt;- xgb_spec_tbl$.models\n\n# Preview first 2 specs\nxgb_model_list[1:2]\n\n[[1]]\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  min_n = 2\n  tree_depth = 2\n  learn_rate = 0.001\n  loss_reduction = 0\n\nComputational engine: xgboost \n\n\n[[2]]\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  min_n = 2\n  tree_depth = 2\n  learn_rate = 0.001\n  loss_reduction = 0.01\n\nComputational engine: xgboost"
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#workflow-sets",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#workflow-sets",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "8 Workflow sets",
    "text": "8 Workflow sets\nWorkflow sets allow us to systematically combine preprocessing recipes and model specifications into comparable modeling pipelines. In this case, we pair a single time-series recipe with multiple XGBoost configurations, creating a collection of untrained workflows that can be fit and evaluated consistently.\n\n# ------------------------------------------------------------------------------\n# Workflow sets\n# - Combine the preprocessing recipe with multiple XGBoost model specifications\n# - Each workflow represents one unique recipe–model combination\n# - Workflows are created unfitted and will be trained during evaluation\n# ------------------------------------------------------------------------------\n\nsales_workflow_set &lt;- workflow_set(\n  preproc = list(sales_recipe = sales_recipe),\n  models  = xgb_model_list,\n  cross   = TRUE\n)\n\n# Inspect the workflow set\nsales_workflow_set"
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#fitting-using-parallel-backend",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#fitting-using-parallel-backend",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "9 Fitting Using Parallel Backend",
    "text": "9 Fitting Using Parallel Backend\nWe will now train all recipe–model combinations by fitting the workflow set on the training portion of the time series. By enabling parallel execution, each workflow is trained concurrently across multiple CPU cores, significantly reducing total runtime while providing clear progress feedback during the fitting process.\n\n# ------------------------------------------------------------------------------\n# Parallel model training (workflow set fitting)\n# - Fit all workflows on the training data\n# - Enable parallel processing to speed up computation\n# - Verbose output shows progress for each workflow\n# ------------------------------------------------------------------------------\n\nfitted_models_tbl &lt;- sales_workflow_set |&gt;\n  modeltime_fit_workflowset(\n    data = training(sales_split),\n    control = control_fit_workflowset(\n      verbose   = TRUE,  # Display progress during fitting\n      allow_par = TRUE   # Use the active parallel backend\n    )\n  )\n\nUsing existing parallel backend with 2 workers...\n\n\n Beginning Parallel Loop | 0.008 seconds\n\n\n Finishing parallel backend. Clusters are remaining open. | 7.514 seconds\n\n\n Close clusters by running: `parallel_stop()`.\n\n\n Total time | 7.514 seconds\n\n# Inspect fitted workflows\nfitted_models_tbl"
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#accuracy-assessment",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#accuracy-assessment",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "10 Accuracy assessment",
    "text": "10 Accuracy assessment\nAfter fitting the models, we evaluate their out-of-sample performance by calibrating each workflow on the test set and computing standard forecast accuracy metrics. Comparing these results allows us to identify the best-performing configuration, with Model 277 achieving the lowest Mean Absolute Error (MAE) and therefore providing the most accurate forecasts on unseen data.\n\n# ------------------------------------------------------------------------------\n# Model evaluation and accuracy comparison\n# - Calibrate fitted models on the test set\n# - Compute standard forecast accuracy metrics\n# - Rank models to identify the best performer\n# ------------------------------------------------------------------------------\n\ncalibration_tbl &lt;- fitted_models_tbl |&gt;\n  modeltime_calibrate(new_data = testing(sales_split))\n\nmodel_accuracy_tbl &lt;- calibration_tbl |&gt;\n  modeltime_accuracy() |&gt;\n  arrange(mae) |&gt; \n  slice_min(mae, n =10)\n\n# Display accuracy results in a readable table\ntable_modeltime_accuracy(\n  model_accuracy_tbl,\n  .interactive = FALSE\n)\n\n\n\n\n\n\n\nAccuracy Table\n\n\n.model_id\n.model_desc\n.type\nmae\nmape\nmase\nsmape\nrmse\nrsq\n\n\n\n\n277\nSALES_RECIPE_BOOST_TREE_277\nTest\n43447.35\n18.21\n0.65\n18.77\n53267.77\n0.36\n\n\n278\nSALES_RECIPE_BOOST_TREE_278\nTest\n43447.35\n18.21\n0.65\n18.77\n53267.77\n0.36\n\n\n279\nSALES_RECIPE_BOOST_TREE_279\nTest\n43447.35\n18.21\n0.65\n18.77\n53267.77\n0.36\n\n\n280\nSALES_RECIPE_BOOST_TREE_280\nTest\n43447.35\n18.21\n0.65\n18.77\n53267.77\n0.36\n\n\n261\nSALES_RECIPE_BOOST_TREE_261\nTest\n43564.50\n18.25\n0.65\n18.68\n54005.01\n0.32\n\n\n262\nSALES_RECIPE_BOOST_TREE_262\nTest\n43564.50\n18.25\n0.65\n18.68\n54005.01\n0.32\n\n\n263\nSALES_RECIPE_BOOST_TREE_263\nTest\n43564.50\n18.25\n0.65\n18.68\n54005.01\n0.32\n\n\n264\nSALES_RECIPE_BOOST_TREE_264\nTest\n43564.50\n18.25\n0.65\n18.68\n54005.01\n0.32\n\n\n257\nSALES_RECIPE_BOOST_TREE_257\nTest\n44264.16\n18.58\n0.66\n19.17\n55486.98\n0.28\n\n\n258\nSALES_RECIPE_BOOST_TREE_258\nTest\n44264.16\n18.58\n0.66\n19.17\n55486.98\n0.28\n\n\n259\nSALES_RECIPE_BOOST_TREE_259\nTest\n44264.16\n18.58\n0.66\n19.17\n55486.98\n0.28\n\n\n260\nSALES_RECIPE_BOOST_TREE_260\nTest\n44264.16\n18.58\n0.66\n19.17\n55486.98\n0.28"
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#forecast-assessment",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#forecast-assessment",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "11 Forecast Assessment",
    "text": "11 Forecast Assessment\nTo complement the numerical accuracy metrics, we visually assess how each model’s forecasts compare against the actual sales during the testing period. This side-by-side visualization helps reveal differences in trend capture, responsiveness to changes, and overall forecast stability that may not be fully apparent from error metrics alone.\n\n# ------------------------------------------------------------------------------\n# Forecast assessment (visual comparison on test set)\n# - Generate forecasts for each fitted model on the test period\n# - Overlay predictions with actual historical sales\n# - Retain underlying data for further inspection if needed\n# ------------------------------------------------------------------------------\n\nforecast_comparison_tbl &lt;- calibration_tbl |&gt;\n  # filter for the 10 best models \n  filter(.model_id %in% model_accuracy_tbl$.model_id) |&gt; \n  modeltime_forecast(\n    new_data    = testing(sales_split),\n    actual_data = cleaned_sales_df,\n    keep_data   = TRUE\n  )\n\n# Plot forecasts vs actuals for visual evaluation\nforecast_comparison_tbl |&gt;\n  plot_modeltime_forecast(\n    .legend_max_width = 10, # For mobile screens\n    .conf_interval_show = FALSE,\n    .title = \"Model Forecasts vs Actual Sales (Test Set)\"\n  )"
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#refit-to-full-dataset-forecast-forward",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#refit-to-full-dataset-forecast-forward",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "12 Refit to Full Dataset & Forecast Forward",
    "text": "12 Refit to Full Dataset & Forecast Forward\nAfter ranking models on the test set, we select the top performer (lowest MAE) and then refit it using the full cleaned dataset so it can learn from all available history. Finally, we generate a 24-month ahead forecast and plot it alongside the historical sales to visualize the expected future trajectory.\n\n# ------------------------------------------------------------------------------\n# Select the best model (lowest MAE)\n# - slice_min() can return ties, so we break ties deterministically with_mae then\n#   take the first row.\n# ------------------------------------------------------------------------------\n\nbest_model_id &lt;- model_accuracy_tbl |&gt;\n  arrange(mae, .model_id) |&gt;\n  slice_head(n = 1) |&gt;\n  pull(.model_id)\n\n# ------------------------------------------------------------------------------\n# Refit the winning model on the full dataset\n# - Re-training on all history improves the final model before forecasting\n# ------------------------------------------------------------------------------\n\nfinal_xgb_tbl &lt;- calibration_tbl |&gt;\n  filter(.model_id == best_model_id) |&gt;\n  modeltime_refit(data = cleaned_sales_df)\n\n# ------------------------------------------------------------------------------\n# Forecast the next 24 months and visualize\n# ------------------------------------------------------------------------------\n\nfuture_forecast_tbl &lt;- final_xgb_tbl |&gt;\n  modeltime_forecast(\n    h = \"24 months\",\n    actual_data = cleaned_sales_df\n  )\n\nfuture_forecast_tbl |&gt;\n  plot_modeltime_forecast(\n    .legend_show = FALSE,\n    .title = \"Final XGBoost Sales Forecast for Product Y (24-Month Horizon)\",\n    .y_lab = \"Sales in USD\"\n  )\n\n\n\n\n# Forecasts dataset\nfuture_forecast_tbl |&gt; \n  filter(.key == \"prediction\") |&gt; \n  select(\n    date = .index, \n    lower_limit = .conf_lo,\n    point_estimate = .value,\n    upper_limit = .conf_hi\n  )\n\n\n  \n\n\n\n\nparallel_stop()"
  },
  {
    "objectID": "blogs/001-hyperparameter-tuning-example/index.html#conclusion",
    "href": "blogs/001-hyperparameter-tuning-example/index.html#conclusion",
    "title": "Sales Forecasting with Machine Learning in R",
    "section": "13 Conclusion",
    "text": "13 Conclusion\nIn this post, we walked through an end-to-end machine learning workflow for sales forecasting in R, starting from data exploration and anomaly detection, through feature engineering, model specification, parallel training, evaluation, and finally producing a forward-looking forecast using XGBoost. This approach offers clear benefits: it leverages rich time-based features, uses a robust validation strategy, and produces forecasts that are both data-driven and reproducible. At the same time, it’s important to recognize the limitations, machine learning models like XGBoost can be sensitive to hyperparameter choices, require careful feature engineering, and may not always generalize best across all datasets or business contexts.\nFor Metricon, these forecasts can directly inform decisions such as inventory planning, budgeting, production scheduling, and scenario analysis by providing a clearer view of expected future demand. However, no single model is universally optimal. In the next post, we’ll broaden the analysis by training and comparing multiple forecasting algorithms on the same sales data to assess whether alternative models can outperform XGBoost and under what conditions, bringing us closer to a truly model-agnostic, decision-ready forecasting strategy.\nWritten by\nGeorge Mwangi is a software engineer and data professional specializing in machine learning, data analytics, and digital health systems design & development. His work focuses on building practical, production-ready solutions for forecasting, decision support, and data-driven planning. He is particularly interested in applying modern data science tools to solve real-world business and public health sector problems.\n\nYou can connect with George on:\n\nLinkedIn: https://www.linkedin.com/in/georgemwangikenya\nGitHub: https://github.com/mwangi-george\n\n\n\nSession Information\n\n\n\n\nsessionInfo()\n\nR version 4.5.2 (2025-10-31)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Tahoe 26.2\n\nMatrix products: default\nBLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Africa/Nairobi\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.4    timetk_2.9.0       modeltime_1.3.2    yardstick_1.3.2   \n [5] workflowsets_1.1.1 workflows_1.3.0    tune_2.0.0         tidyr_1.3.1       \n [9] tailor_0.1.0       rsample_1.3.1      recipes_1.3.1      purrr_1.1.0       \n[13] parsnip_1.3.3      modeldata_1.5.1    infer_1.0.9        ggplot2_3.5.2     \n[17] dplyr_1.1.4        dials_1.4.2        scales_1.4.0       broom_1.0.10      \n[21] tidymodels_1.4.1  \n\nloaded via a namespace (and not attached):\n [1] rlang_1.1.6         magrittr_2.0.3      furrr_0.3.1        \n [4] compiler_4.5.2      vctrs_0.6.5         lhs_1.2.0          \n [7] stringr_1.5.1       pkgconfig_2.0.3     fastmap_1.2.0      \n[10] backports_1.5.0     labeling_0.4.3      rmarkdown_2.29     \n[13] prodlim_2025.04.28  xfun_0.52           jsonlite_2.0.0     \n[16] parallel_4.5.2      R6_2.6.1            stringi_1.8.7      \n[19] RColorBrewer_1.1-3  StanHeaders_2.32.10 parallelly_1.45.0  \n[22] rpart_4.1.24        xgboost_1.7.11.1    Rcpp_1.0.14        \n[25] iterators_1.0.14    knitr_1.50          future.apply_1.20.0\n[28] zoo_1.8-14          Matrix_1.7-4        splines_4.5.2      \n[31] nnet_7.3-20         timechange_0.3.0    tidyselect_1.2.1   \n[34] rstudioapi_0.17.1   yaml_2.3.10         timeDate_4041.110  \n[37] doParallel_1.0.17   codetools_0.2-20    listenv_0.9.1      \n[40] lattice_0.22-7      tibble_3.3.0        withr_3.0.2        \n[43] evaluate_1.0.4      future_1.58.0       survival_3.8-3     \n[46] RcppParallel_5.1.10 xml2_1.3.8          xts_0.14.1         \n[49] pillar_1.10.2       foreach_1.5.2       plotly_4.11.0      \n[52] generics_0.1.4      globals_0.18.0      class_7.3-23       \n[55] glue_1.8.0          lazyeval_0.2.2      tools_4.5.2        \n[58] data.table_1.17.6   gower_1.0.2         forcats_1.0.0      \n[61] fs_1.6.6            grid_4.5.2          crosstalk_1.2.1    \n[64] ipred_0.9-15        cli_3.6.5           DiceDesign_1.10    \n[67] viridisLite_0.4.2   lava_1.8.1          gt_1.1.0           \n[70] gtable_0.3.6        GPfit_1.0-9         sass_0.4.10        \n[73] digest_0.6.37       htmlwidgets_1.6.4   farver_2.1.2       \n[76] htmltools_0.5.8.1   lifecycle_1.0.4     hardhat_1.4.2      \n[79] httr_1.4.7          MASS_7.3-65         sparsevctrs_0.3.4"
  }
]